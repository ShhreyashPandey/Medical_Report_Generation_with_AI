This project utilizes deep learning to automate disease classification and view position identification in chest X-ray images, enhancing diagnostic accuracy and efficiency. Built on DenseNet, a state-of-the-art convolutional neural network, the model accurately identifies diseases and view positions. In order to improve interpretability and clinician trust, it uses explainable AI techniques such as LIME and GRAD-CAM to visually emphasise diagnostic regions. The system generates detailed radiology reports, by combining classification results, diagnostic areas, and patient data, offering radiologists with a useful tool to help them make fast and accurate judgements.

![Screenshot 2024-11-16 142646](https://github.com/user-attachments/assets/e36849b0-5409-4a5e-8601-b03eeb6e020b)
