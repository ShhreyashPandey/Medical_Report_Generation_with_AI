This project utilizes deep learning to automate disease classification and view position identification in chest X-ray images, enhancing diagnostic accuracy and efficiency. Built on DenseNet, a state-of-the-art convolutional neural network, the model accurately identifies diseases and view positions. It incorporates explainable AI techniques like LIME and GRAD-CAM to visually highlight diagnostic regions, improving interpretability and clinician trust. The system generates detailed radiology reports, combining classification results, diagnostic areas, and patient data, offering a valuable tool to assist radiologists in making informed, reliable decisions quickly and effectively.
